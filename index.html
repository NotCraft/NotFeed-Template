<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-08-27T01:30:00Z">08-27</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">With One Voice: Composing a Travel Voice Assistant from Re-purposed Models. (arXiv:2108.11463v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11463">
<div class="article-summary-box-inner">
<span><p>Voice assistants provide users a new way of interacting with digital
products, allowing them to retrieve information and complete tasks with an
increased sense of control and flexibility. Such products are comprised of
several machine learning models, like Speech-to-Text transcription, Named
Entity Recognition and Resolution, and Text Classification. Building a voice
assistant from scratch takes the prolonged efforts of several teams
constructing numerous models and orchestrating between components. Alternatives
such as using third-party vendors or re-purposing existing models may be
considered to shorten time-to-market and development costs. However, each
option has its benefits and drawbacks. We present key insights from building a
voice search assistant for Booking.com search and recommendation system. Our
paper compares the achieved performance and development efforts in dedicated
tailor-made solutions against existing re-purposed models. We share and discuss
our data-driven decisions about implementation trade-offs and their estimated
outcomes in hindsight, showing that a fully functional machine learning product
can be built from existing models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Attention in Machine Reading Comprehension. (arXiv:2108.11574v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11574">
<div class="article-summary-box-inner">
<span><p>Achieving human-level performance on some of Machine Reading Comprehension
(MRC) datasets is no longer challenging with the help of powerful Pre-trained
Language Models (PLMs). However, the internal mechanism of these artifacts
still remains unclear, placing an obstacle for further understanding these
models. This paper focuses on conducting a series of analytical experiments to
examine the relations between the multi-head self-attention and the final
performance, trying to analyze the potential explainability in PLM-based MRC
models. We perform quantitative analyses on SQuAD (English) and CMRC 2018
(Chinese), two span-extraction MRC datasets, on top of BERT, ALBERT, and
ELECTRA in various aspects. We discover that {\em passage-to-question} and {\em
passage understanding} attentions are the most important ones, showing strong
correlations to the final performance than other parts. Through visualizations
and case studies, we also observe several general findings on the attention
maps, which could be helpful to understand how these models solve the
questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AVATAR: A Parallel Corpus for Java-Python Program Translation. (arXiv:2108.11590v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11590">
<div class="article-summary-box-inner">
<span><p>Program translation refers to migrating source code from one programming
language to another. It has a tremendous practical value in software
development as porting software across different languages is time-consuming
and costly. Automating program translation is of paramount importance in
software migration, and recently researchers explored unsupervised approaches
due to the unavailability of parallel corpora. However, the availability of
pre-trained language models for programming languages enable supervised
fine-tuning with a small amount of labeled examples. In this work, we present a
corpus of 8,475 programming problems and their solutions written in two popular
languages, Java and Python. We collect the dataset from competitive programming
sites, online platforms, and open source repositories. We present several
baselines, including models trained from scratch or pre-trained on large-scale
source code collection and fine-tuned on our proposed dataset. Experiment
results show that while the models perform relatively well in terms of the
lexical match, they lack in generating code that is accurate in terms of syntax
and data-flow match.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LayoutReader: Pre-training of Text and Layout for Reading Order Detection. (arXiv:2108.11591v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11591">
<div class="article-summary-box-inner">
<span><p>Reading order detection is the cornerstone to understanding visually-rich
documents (e.g., receipts and forms). Unfortunately, no existing work took
advantage of advanced deep learning models because it is too laborious to
annotate a large enough dataset. We observe that the reading order of WORD
documents is embedded in their XML metadata; meanwhile, it is easy to convert
WORD documents to PDFs or images. Therefore, in an automated manner, we
construct ReadingBank, a benchmark dataset that contains reading order, text,
and layout information for 500,000 document images covering a wide spectrum of
document types. This first-ever large-scale dataset unleashes the power of deep
neural networks for reading order detection. Specifically, our proposed
LayoutReader captures the text and layout information for reading order
prediction using the seq2seq model. It performs almost perfectly in reading
order detection and significantly improves both open-source and commercial OCR
engines in ordering text lines in their results in our experiments. We will
release the dataset and model at \url{https://aka.ms/readingbank}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Retrieval Augmented Code Generation and Summarization. (arXiv:2108.11601v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11601">
<div class="article-summary-box-inner">
<span><p>Software developers write a lot of source code and documentation during
software development. Intrinsically, developers often recall parts of source
code or code summaries that they had written in the past while implementing
software or documenting them. To mimic developers' code or summary generation
behavior, we propose a retrieval augmented framework, \tool, that retrieves
relevant code or summaries from a retrieval database and provides them as a
supplement to code generation or summarization models. \tool has a couple of
uniqueness. First, it extends the state-of-the-art dense retrieval technique to
search for relevant code or summaries. Second, it can work with retrieval
databases that include unimodal (only code or natural language description) or
bimodal instances (code-description pairs). We conduct experiments and
extensive analysis on two benchmark datasets of code generation and
summarization in Java and Python, and the promising results endorse the
effectiveness of our proposed retrieval augmented framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Negative Sampling for Unlabeled Entity Problem in Named Entity Recognition. (arXiv:2108.11607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11607">
<div class="article-summary-box-inner">
<span><p>In many situations (e.g., distant supervision), unlabeled entity problem
seriously degrades the performances of named entity recognition (NER) models.
Recently, this issue has been well addressed by a notable approach based on
negative sampling. In this work, we perform two studies along this direction.
Firstly, we analyze why negative sampling succeeds both theoretically and
empirically. Based on the observation that named entities are highly sparse in
datasets, we show a theoretical guarantee that, for a long sentence, the
probability of containing no unlabeled entities in sampled negatives is high.
Missampling tests on synthetic datasets have verified our guarantee in
practice. Secondly, to mine hard negatives and further reduce missampling
rates, we propose a weighted and adaptive sampling distribution for negative
sampling. Experiments on synthetic datasets and well-annotated datasets show
that our method significantly improves negative sampling in robustness and
effectiveness. We also have achieved new state-of-the-art results on real-world
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation. (arXiv:2108.11626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11626">
<div class="article-summary-box-inner">
<span><p>As the use of interactive machines grow, the task of Emotion Recognition in
Conversation (ERC) became more important. If the machine generated sentences
reflect emotion, more human-like sympathetic conversations are possible. Since
emotion recognition in conversation is inaccurate if the previous utterances
are not taken into account, many studies reflect the dialogue context to
improve the performances. We introduce CoMPM, a context embedding module (CoM)
combined with a pre-trained memory module (PM) that tracks memory of the
speaker's previous utterances within the context, and show that the pre-trained
memory significantly improves the final accuracy of emotion recognition. We
experimented on both the multi-party datasets (MELD, EmoryNLP) and the
dyadic-party datasets (IEMOCAP, DailyDialog), showing that our approach achieve
competitive performance on all datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scalable End-to-End Training of Knowledge Graph-Enhanced Aspect Embedding for Aspect Level Sentiment Analysis. (arXiv:2108.11656v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11656">
<div class="article-summary-box-inner">
<span><p>Aspect level sentiment classification (ALSC) is a difficult problem with
state-of-the-art models showing less than 80% macro-F1 score on benchmark
datasets. Existing models do not incorporate information on aspect-aspect
relations in knowledge graphs (KGs), e.g. DBpedia. Two main challenges stem
from inaccurate disambiguation of aspects to KG entities, and the inability to
learn aspect representations from the large KGs in joint training with ALSC
models.
</p>
<p>We propose a two-level global-local entity embedding scheme that allows
efficient joint training of KG-based aspect embeddings and ALSC models. A novel
incorrect disambiguation detection technique addresses the problem of
inaccuracy in aspect disambiguation. The proposed methods show a consistent
improvement of $2.5 - 4.1$ percentage points, over the recent BERT-based
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Technological Approaches to Detecting Online Disinformation and Manipulation. (arXiv:2108.11669v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11669">
<div class="article-summary-box-inner">
<span><p>The move of propaganda and disinformation to the online environment is
possible thanks to the fact that within the last decade, digital information
channels radically increased in popularity as a news source. The main advantage
of such media lies in the speed of information creation and dissemination.
This, on the other hand, inevitably adds pressure, accelerating editorial work,
fact-checking, and the scrutiny of source credibility. In this chapter, an
overview of computer-supported approaches to detecting disinformation and
manipulative techniques based on several criteria is presented. We concentrate
on the technical aspects of automatic methods which support fact-checking,
topic identification, text style analysis, or message filtering on social media
channels. Most of the techniques employ artificial intelligence and machine
learning with feature extraction combining available information resources. The
following text firstly specifies the tasks related to computer detection of
manipulation and disinformation spreading. The second section presents concrete
methods of solving the tasks of the analysis, and the third sections enlists
current verification and benchmarking datasets published and used in this area
for evaluation and comparison.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rethinking Why Intermediate-Task Fine-Tuning Works. (arXiv:2108.11696v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11696">
<div class="article-summary-box-inner">
<span><p>Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a
widely applied technique, which first fine-tunes the pretrained language models
on an intermediate task before on the target task of interest. While STILTs is
able to further improve the performance of pretrained language models, it is
still unclear why and when it works. Previous research shows that those
intermediate tasks involving complex inference, such as commonsense reasoning,
work especially well for RoBERTa. In this paper, we discover that the
improvement from an intermediate task could be orthogonal to it containing
reasoning or other complex skills -- a simple real-fake discrimination task
synthesized by GPT2 can benefit diverse target tasks. We conduct extensive
experiments to study the impact of different factors on STILTs. These findings
suggest rethinking the role of intermediate fine-tuning in the STILTs pipeline.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation for Low-Resource Named Entity Recognition Using Backtranslation. (arXiv:2108.11703v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11703">
<div class="article-summary-box-inner">
<span><p>The state of art natural language processing systems relies on sizable
training datasets to achieve high performance. Lack of such datasets in the
specialized low resource domains lead to suboptimal performance. In this work,
we adapt backtranslation to generate high quality and linguistically diverse
synthetic data for low-resource named entity recognition. We perform
experiments on two datasets from the materials science (MaSciP) and biomedical
domains (S800). The empirical results demonstrate the effectiveness of our
proposed augmentation strategy, particularly in the low-resource scenario.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Statutory Article Retrieval Dataset in French. (arXiv:2108.11792v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11792">
<div class="article-summary-box-inner">
<span><p>Statutory article retrieval is the task of automatically retrieving law
articles relevant to a legal question. While recent advances in natural
language processing have sparked considerable interest in many legal tasks,
statutory article retrieval remains primarily untouched due to the scarcity of
large-scale and high-quality annotated datasets. To address this bottleneck, we
introduce the Belgian Statutory Article Retrieval Dataset (BSARD), which
consists of 1,100+ French native legal questions labeled by experienced jurists
with relevant articles from a corpus of 22,600+ Belgian law articles. Using
BSARD, we benchmark several unsupervised information retrieval methods based on
term weighting and pooled embeddings. Our best performing baseline achieves
50.8% R@100, which is promising for the feasibility of the task and indicates
that there is still substantial room for improvement. By the specificity of the
data domain and addressed task, BSARD presents a unique challenge problem for
future research on legal information retrieval.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-tuning Pretrained Language Models with Label Attention for Explainable Biomedical Text Classification. (arXiv:2108.11809v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11809">
<div class="article-summary-box-inner">
<span><p>The massive growth of digital biomedical data is making biomedical text
indexing and classification increasingly important. Accordingly, previous
research has devised numerous techniques ranging from rule-based systems to
deep neural networks, with most focusing on feedforward, convolutional or
recurrent neural architectures. More recently, fine-tuned transformers-based
pretrained models (PTMs) have demonstrated superior performance in many natural
language processing tasks. However, the direct use of PTMs in the biomedical
domain is only limited to the target documents, ignoring the rich semantic
information in the label descriptions. In this paper, we develop an improved
label attention-based architecture to inject semantic label description into
the fine-tuning process of PTMs. Results on two public medical datasets show
that the proposed fine-tuning scheme outperforms the conventionally fine-tuned
PTMs and prior state-of-the-art models. Furthermore, we show that fine-tuning
with the label attention mechanism is interpretable in the interpretability
study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Computational Approach to Measure Empathy and Theory-of-Mind from Written Texts. (arXiv:2108.11810v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11810">
<div class="article-summary-box-inner">
<span><p>Theory-of-mind (ToM), a human ability to infer the intentions and thoughts of
others, is an essential part of empathetic experiences. We provide here the
framework for using NLP models to measure ToM expressed in written texts. For
this purpose, we introduce ToM-Diary, a crowdsourced 18,238 diaries with 74,014
Korean sentences annotated with different ToM levels. Each diary was annotated
with ToM levels by trained psychology students and reviewed by selected
psychology experts. The annotators first divided the diaries based on whether
they mentioned other people: self-focused and other-focused. Examples of
self-focused sentences are "I am feeling good". The other-focused sentences
were further classified into different levels. These levels differ by whether
the writer 1) mentions the presence of others without inferring their mental
state(e.g., I saw a man walking down the street), 2) fails to take the
perspective of others (e.g., I don't understand why they refuse to wear masks),
or 3) successfully takes the perspective of others (It must have been hard for
them to continue working). We tested whether state-of-the-art transformer-based
models (e.g., BERT) could predict underlying ToM levels in sentences. We found
that BERT more successfully detected self-focused sentences than other-focused
ones. Sentences that successfully take the perspective of others (the highest
ToM level) were the most difficult to predict. Our study suggests a promising
direction for large-scale and computational approaches for identifying the
ability of authors to empathize and take the perspective of others. The dataset
is at [URL](https://github.com/humanfactorspsych/covid19-tom-empathy-diary)
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts. (arXiv:2108.11830v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11830">
<div class="article-summary-box-inner">
<span><p>Dialogue models trained on human conversations inadvertently learn to
generate offensive responses. Moreover, models can insult anyone by agreeing
with an offensive context. To understand the dynamics of contextually offensive
language, we study the stance of dialogue model responses in offensive Reddit
conversations. Specifically, we crowd-annotate ToxiChat, a new dataset of 2,000
Reddit threads and model responses labeled with offensive language and stance.
Our analysis reveals that 42% of user responses agree with toxic comments; 3x
their agreement with safe comments (13%). Pre-trained transformer-based
classifiers fine-tuned on our dataset achieve 0.71 F1 for offensive labels and
0.53 Macro-F1 for stance labels. Finally, we analyze some existing controllable
text generation (CTG) methods to mitigate the contextual offensive behavior of
dialogue models. Compared to the baseline, our best CTG model obtains a 19%
reduction in agreement with offensive context and 29% fewer offensive
responses. This highlights the need for future work to characterize and analyze
more forms of inappropriate behavior in dialogue models to help make them
safer. Our code and corpus are available at
https://github.com/abaheti95/ToxiChat .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Alleviating Exposure Bias via Contrastive Learning for Abstractive Text Summarization. (arXiv:2108.11846v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11846">
<div class="article-summary-box-inner">
<span><p>Encoder-decoder models have achieved remarkable success in abstractive text
summarization, which aims to compress one or more documents into a shorter
version without the loss of the essential content. Unfortunately, these models
mostly suffer a discrepancy between training and inference, i.e., the exposure
bias problem. During the training stage, with teacher forcing these models are
optimized to maximize the likelihood of the gold summary given the gold summary
tokens as input to the decoder, while at inference the given tokens are
replaced by the generated tokens. Consequently, low-quality summaries are very
likely to be generated. To remedy this problem, we propose to leverage
contrastive learning to decrease the likelihood of these low-quality summaries,
and meanwhile increase the likelihood of the gold summary. Since our solution
expands the states that the model perceives during training, we expect that the
exposure bias problem can be alleviated. We experimentally demonstrate that our
method effectively improves the performance of the state-of-the-art model on
different datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Realistic Study of Auto-regressive Language Models for Named Entity Typing and Recognition. (arXiv:2108.11857v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11857">
<div class="article-summary-box-inner">
<span><p>Despite impressive results of language models for named entity recognition
(NER), their generalization to varied textual genres, a growing entity type
set, and new entities remains a challenge. Collecting thousands of annotations
in each new case for training or fine-tuning is expensive and time-consuming.
In contrast, humans can easily identify named entities given some simple
instructions. Inspired by this, we challenge the reliance on large datasets and
study pre-trained language models for NER in a meta-learning setup. First, we
test named entity typing (NET) in a zero-shot transfer scenario. Then, we
perform NER by giving few examples at inference. We propose a method to select
seen and rare / unseen names when having access only to the pre-trained model
and report results on these groups. The results show: auto-regressive language
models as meta-learners can perform NET and NER fairly well especially for
regular or seen names; name irregularity when often present for a certain
entity type can become an effective exploitable cue; names with words foreign
to the model have the most negative impact on results; the model seems to rely
more on name than context cues in few-shot NER.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Survey on Automated Fact-Checking. (arXiv:2108.11896v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11896">
<div class="article-summary-box-inner">
<span><p>Fact-checking has become increasingly important due to the speed with which
both information and misinformation can spread in the modern media ecosystem.
Therefore, researchers have been exploring how fact-checking can be automated,
using techniques based on natural language processing, machine learning,
knowledge representation, and databases to automatically predict the veracity
of claims. In this paper, we survey automated fact-checking stemming from
natural language processing, and discuss its connections to related tasks and
disciplines. In this process, we present an overview of existing datasets and
models, aiming to unify the various definitions given and identify common
concepts. Finally, we highlight challenges for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Similar Scenes arouse Similar Emotions: Parallel Data Augmentation for Stylized Image Captioning. (arXiv:2108.11912v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11912">
<div class="article-summary-box-inner">
<span><p>Stylized image captioning systems aim to generate a caption not only
semantically related to a given image but also consistent with a given style
description. One of the biggest challenges with this task is the lack of
sufficient paired stylized data. Many studies focus on unsupervised approaches,
without considering from the perspective of data augmentation. We begin with
the observation that people may recall similar emotions when they are in
similar scenes, and often express similar emotions with similar style phrases,
which underpins our data augmentation idea. In this paper, we propose a novel
Extract-Retrieve-Generate data augmentation framework to extract style phrases
from small-scale stylized sentences and graft them to large-scale factual
captions. First, we design the emotional signal extractor to extract style
phrases from small-scale stylized sentences. Second, we construct the plugable
multi-modal scene retriever to retrieve scenes represented with pairs of an
image and its stylized caption, which are similar to the query image or caption
in the large-scale factual data. In the end, based on the style phrases of
similar scenes and the factual description of the current scene, we build the
emotion-aware caption generator to generate fluent and diversified stylized
captions for the current scene. Extensive experimental results show that our
framework can alleviate the data scarcity problem effectively. It also
significantly boosts the performance of several existing image captioning
models in both supervised and unsupervised settings, which outperforms the
state-of-the-art stylized image captioning methods in terms of both sentence
relevance and stylishness by a substantial margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HAN: Higher-order Attention Network for Spoken Language Understanding. (arXiv:2108.11916v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11916">
<div class="article-summary-box-inner">
<span><p>Spoken Language Understanding (SLU), including intent detection and slot
filling, is a core component in human-computer interaction. The natural
attributes of the relationship among the two subtasks make higher requirements
on fine-grained feature interaction, i.e., the token-level intent features and
slot features. Previous works mainly focus on jointly modeling the relationship
between the two subtasks with attention-based models, while ignoring the
exploration of attention order. In this paper, we propose to replace the
conventional attention with our proposed Bilinear attention block and show that
the introduced Higher-order Attention Network (HAN) brings improvement for the
SLU task. Importantly, we conduct wide analysis to explore the effectiveness
brought from the higher-order attention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Machine Learning for Mediation in Armed Conflicts. (arXiv:2108.11942v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11942">
<div class="article-summary-box-inner">
<span><p>Today's conflicts are becoming increasingly complex, fluid and fragmented,
often involving a host of national and international actors with multiple and
often divergent interests. This development poses significant challenges for
conflict mediation, as mediators struggle to make sense of conflict dynamics,
such as the range of conflict parties and the evolution of their political
positions, the distinction between relevant and less relevant actors in peace
making, or the identification of key conflict issues and their interdependence.
International peace efforts appear increasingly ill-equipped to successfully
address these challenges. While technology is being increasingly used in a
range of conflict related fields, such as conflict predicting or information
gathering, less attention has been given to how technology can contribute to
conflict mediation. This case study is the first to apply state-of-the-art
machine learning technologies to data from an ongoing mediation process. Using
dialogue transcripts from peace negotiations in Yemen, this study shows how
machine-learning tools can effectively support international mediators by
managing knowledge and offering additional conflict analysis tools to assess
complex information. Apart from illustrating the potential of machine learning
tools in conflict mediation, the paper also emphasises the importance of
interdisciplinary and participatory research design for the development of
context-sensitive and targeted tools and to ensure meaningful and responsible
implementation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Position-Invariant Truecasing with a Word-and-Character Hierarchical Recurrent Neural Network. (arXiv:2108.11943v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11943">
<div class="article-summary-box-inner">
<span><p>Truecasing is the task of restoring the correct case (uppercase or lowercase)
of noisy text generated either by an automatic system for speech recognition or
machine translation or by humans. It improves the performance of downstream NLP
tasks such as named entity recognition and language modeling. We propose a
fast, accurate and compact two-level hierarchical word-and-character-based
recurrent neural network model, the first of its kind for this problem. Using
sequence distillation, we also address the problem of truecasing while ignoring
token positions in the sentence, i.e. in a position-invariant manner.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SASRA: Semantically-aware Spatio-temporal Reasoning Agent for Vision-and-Language Navigation in Continuous Environments. (arXiv:2108.11945v1 [cs.RO])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11945">
<div class="article-summary-box-inner">
<span><p>This paper presents a novel approach for the Vision-and-Language Navigation
(VLN) task in continuous 3D environments, which requires an autonomous agent to
follow natural language instructions in unseen environments. Existing
end-to-end learning-based VLN methods struggle at this task as they focus
mostly on utilizing raw visual observations and lack the semantic
spatio-temporal reasoning capabilities which is crucial in generalizing to new
environments. In this regard, we present a hybrid transformer-recurrence model
which focuses on combining classical semantic mapping techniques with a
learning-based method. Our method creates a temporal semantic memory by
building a top-down local ego-centric semantic map and performs cross-modal
grounding to align map and language modalities to enable effective learning of
VLN policy. Empirical results in a photo-realistic long-horizon simulation
environment show that the proposed approach outperforms a variety of
state-of-the-art methods and baselines with over 22% relative improvement in
SPL in prior unseen environments.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SAUCE: Truncated Sparse Document Signature Bit-Vectors for Fast Web-Scale Corpus Expansion. (arXiv:2108.11948v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11948">
<div class="article-summary-box-inner">
<span><p>Recent advances in text representation have shown that training on large
amounts of text is crucial for natural language understanding. However, models
trained without predefined notions of topical interest typically require
careful fine-tuning when transferred to specialized domains. When a sufficient
amount of within-domain text may not be available, expanding a seed corpus of
relevant documents from large-scale web data poses several challenges. First,
corpus expansion requires scoring and ranking each document in the collection,
an operation that can quickly become computationally expensive as the web
corpora size grows. Relying on dense vector spaces and pairwise similarity adds
to the computational expense. Secondly, as the domain concept becomes more
nuanced, capturing the long tail of domain-specific rare terms becomes
non-trivial, especially under limited seed corpora scenarios.
</p>
<p>In this paper, we consider the problem of fast approximate corpus expansion
given a small seed corpus with a few relevant documents as a query, with the
goal of capturing the long tail of a domain-specific set of concept terms. To
efficiently collect large-scale domain-specific corpora with limited relevance
feedback, we propose a novel truncated sparse document bit-vector
representation, termed Signature Assisted Unsupervised Corpus Expansion
(SAUCE). Experimental results show that SAUCE can reduce the computational
burden while ensuring high within-domain lexical coverage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weisfeiler-Leman in the BAMBOO: Novel AMR Graph Metrics and a Benchmark for AMR Graph Similarity. (arXiv:2108.11949v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11949">
<div class="article-summary-box-inner">
<span><p>Several metrics have been proposed for assessing the similarity of (abstract)
meaning representations (AMRs), but little is known about how they relate to
human similarity ratings. Moreover, the current metrics have complementary
strengths and weaknesses: some emphasize speed, while others make the alignment
of graph structures explicit, at the price of a costly alignment step.
</p>
<p>In this work we propose new Weisfeiler-Leman AMR similarity metrics that
unify the strengths of previous metrics, while mitigating their weaknesses.
Specifically, our new metrics are able to match contextualized substructures
and induce n:m alignments between their nodes. Furthermore, we introduce a
Benchmark for AMR Metrics based on Overt Objectives (BAMBOO), the first
benchmark to support empirical assessment of graph-based MR similarity metrics.
BAMBOO maximizes the interpretability of results by defining multiple overt
objectives that range from sentence similarity objectives to stress tests that
probe a metric's robustness against meaning-altering and meaning-preserving
graph transformations. We show the benefits of BAMBOO by profiling previous
metrics and our own metrics. Results indicate that our novel metrics may serve
as a strong baseline for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LocTex: Learning Data-Efficient Visual Representations from Localized Textual Supervision. (arXiv:2108.11950v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11950">
<div class="article-summary-box-inner">
<span><p>Computer vision tasks such as object detection and semantic/instance
segmentation rely on the painstaking annotation of large training datasets. In
this paper, we propose LocTex that takes advantage of the low-cost localized
textual annotations (i.e., captions and synchronized mouse-over gestures) to
reduce the annotation effort. We introduce a contrastive pre-training framework
between images and captions and propose to supervise the cross-modal attention
map with rendered mouse traces to provide coarse localization signals. Our
learned visual features capture rich semantics (from free-form captions) and
accurate localization (from mouse traces), which are very effective when
transferred to various downstream vision tasks. Compared with ImageNet
supervised pre-training, LocTex can reduce the size of the pre-training dataset
by 10x or the target dataset by 2x while achieving comparable or even improved
performance on COCO instance segmentation. When provided with the same amount
of annotations, LocTex achieves around 4% higher accuracy than the previous
state-of-the-art "vision+language" pre-training approach on the task of PASCAL
VOC image classification.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SUMBT+LaRL: Effective Multi-domain End-to-end Neural Task-oriented Dialog System. (arXiv:2009.10447v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10447">
<div class="article-summary-box-inner">
<span><p>The recent advent of neural approaches for developing each dialog component
in task-oriented dialog systems has remarkably improved, yet optimizing the
overall system performance remains a challenge. Besides, previous research on
modeling complicated multi-domain goal-oriented dialogs in end-to-end fashion
has been limited. In this paper, we present an effective multi-domain
end-to-end trainable neural dialog system SUMBT+LaRL that incorporates two
previous strong models and facilitates them to be fully differentiable.
Specifically, the SUMBT+ estimates user-acts as well as dialog belief states,
and the LaRL models latent system action spaces and generates responses given
the estimated contexts. We emphasize that the training framework of three steps
significantly and stably increase dialog success rates: separately pretraining
the SUMBT+ and LaRL, fine-tuning the entire system, and then reinforcement
learning of dialog policy. We also introduce new reward criteria of
reinforcement learning for dialog policy training. Then, we discuss
experimental results depending on the reward criteria and different dialog
evaluation methods. Consequently, our model achieved the new state-of-the-art
success rate of 85.4% on corpus-based evaluation, and a comparable success rate
of 81.40% on simulator-based evaluation provided by the DSTC8 challenge. To our
best knowledge, our work is the first comprehensive study of a modularized E2E
multi-domain dialog system that learning from each component to the entire
dialog policy for task success.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multi-Adversarial Learning for Cross-Lingual Word Embeddings. (arXiv:2010.08432v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08432">
<div class="article-summary-box-inner">
<span><p>Generative adversarial networks (GANs) have succeeded in inducing
cross-lingual word embeddings -- maps of matching words across languages --
without supervision. Despite these successes, GANs' performance for the
difficult case of distant languages is still not satisfactory. These
limitations have been explained by GANs' incorrect assumption that source and
target embedding spaces are related by a single linear mapping and are
approximately isomorphic. We assume instead that, especially across distant
languages, the mapping is only piece-wise linear, and propose a
multi-adversarial learning method. This novel method induces the seed
cross-lingual dictionary through multiple mappings, each induced to fit the
mapping for one subspace. Our experiments on unsupervised bilingual lexicon
induction show that this method improves performance over previous
single-mapping methods, especially for distant languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ONION: A Simple and Effective Defense Against Textual Backdoor Attacks. (arXiv:2011.10369v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10369">
<div class="article-summary-box-inner">
<span><p>Backdoor attacks are a kind of emergent training-time threat to deep neural
networks (DNNs). They can manipulate the output of DNNs and possess high
insidiousness. In the field of natural language processing, some attack methods
have been proposed and achieve very high attack success rates on multiple
popular models. Nevertheless, there are few studies on defending against
textual backdoor attacks. In this paper, we propose a simple and effective
textual backdoor defense named ONION, which is based on outlier word detection
and, to the best of our knowledge, is the first method that can handle all the
textual backdoor attack situations. Experiments demonstrate the effectiveness
of our model in defending BiLSTM and BERT against five different backdoor
attacks. All the code and data will be released to facilitate future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Progressive Transformer-Based Generation of Radiology Reports. (arXiv:2102.09777v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09777">
<div class="article-summary-box-inner">
<span><p>Inspired by Curriculum Learning, we propose a consecutive (i.e.
image-to-text-to-text) generation framework where we divide the problem of
radiology report generation into two steps. Contrary to generating the full
radiology report from the image at once, the model generates global concepts
from the image in the first step and then reforms them into finer and coherent
texts using transformer-based architecture. We follow the transformer-based
sequence-to-sequence paradigm at each step. We improve upon the
state-of-the-art on two benchmark datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Diversity of Neural Text Generation via Inverse Probability Weighting. (arXiv:2103.07649v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07649">
<div class="article-summary-box-inner">
<span><p>The neural text generation suffers from the text degeneration issue such as
repetition. Traditional stochastic sampling methods only focus on truncating
the unreliable "tail" of the distribution, and do not address the "head" part,
which we show might contain tedious or even repetitive candidates with high
probability that lead to repetition loops. They also do not consider the issue
that human text does not always favor high-probability words. Inspired by
these, in this work we propose a heuristic sampling method. We propose to use
interquartile range of the predicted distribution to determine the "head" part,
then permutate and rescale the "head" with inverse probability. This aims at
decreasing the probability for the tedious and possibly repetitive candidates
with higher probability, and increasing the probability for the rational but
more surprising candidates with lower probability. The proposed algorithm
provides a reasonable permutation on the predicted distribution which enhances
diversity without compromising rationality of the distribution. We use
pre-trained language model to compare our algorithm with traditional methods.
Results show that our algorithm can effectively increase the diversity of
generated samples while achieving close resemblance to human text.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections. (arXiv:2104.04670v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04670">
<div class="article-summary-box-inner">
<span><p>Large pre-trained language models (LMs) such as GPT-3 have acquired a
surprising ability to perform zero-shot learning. For example, to classify
sentiment without any training examples, we can "prompt" the LM with the review
and the label description "Does the user like this movie?", and ask whether the
next word is "yes" or "no". However, the next word prediction training
objective is still misaligned with the target zero-shot learning objective. To
address this weakness, we propose meta-tuning, which directly optimizes the
zero-shot learning objective by fine-tuning pre-trained language models on a
collection of datasets. We focus on classification tasks, and construct the
meta-dataset by aggregating 43 existing datasets and annotating 441 label
descriptions in a question-answering (QA) format. When evaluated on unseen
tasks, meta-tuned models outperform a same-sized QA model and the previous SOTA
zero-shot learning system based on natural language inference. Additionally,
increasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%,
and we forecast that even larger models would perform better. Therefore,
measuring zero-shot learning performance on language models out-of-the-box
might underestimate their true potential, and community-wide efforts on
aggregating datasets and unifying their formats can help build models that
answer prompts better.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data-QuestEval: A Referenceless Metric for Data-to-Text Semantic Evaluation. (arXiv:2104.07555v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07555">
<div class="article-summary-box-inner">
<span><p>QuestEval is a reference-less metric used in text-to-text tasks, that
compares the generated summaries directly to the source text, by automatically
asking and answering questions. Its adaptation to Data-to-Text tasks is not
straightforward, as it requires multimodal Question Generation and Answering
systems on the considered tasks, which are seldom available. To this purpose,
we propose a method to build synthetic multimodal corpora enabling to train
multimodal components for a data-QuestEval metric. The resulting metric is
reference-less and multimodal; it obtains state-of-the-art correlations with
human judgment on the WebNLG and WikiBio benchmarks. We make data-QuestEval's
code and models available for reproducibility purpose, as part of the QuestEval
project.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the Power of Saturated Transformers: A View from Circuit Complexity. (arXiv:2106.16213v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16213">
<div class="article-summary-box-inner">
<span><p>Transformers have become a standard architecture for many NLP problems. This
has motivated theoretically analyzing their capabilities as models of language,
in order to understand what makes them successful, and what their potential
weaknesses might be. Recent work has shown that transformers with hard
attention are quite limited in capacity, and in fact can be simulated by
constant-depth circuits. However, hard attention is a restrictive assumption,
which may complicate the relevance of these results for practical transformers.
In this work, we analyze the circuit complexity of transformers with saturated
attention: a generalization of hard attention that more closely captures the
attention patterns learnable in practical transformers. We show that saturated
transformers transcend the limitations of hard-attention transformers. With
some minor assumptions, we prove that the number of bits needed to represent a
saturated transformer memory vector is $O(\log n)$, which implies saturated
transformers can be simulated by log-depth circuits. Thus, the jump from hard
to saturated attention can be understood as increasing the transformer's
effective circuit depth by a factor of $O(\log n)$.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature. (arXiv:2107.01198v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01198">
<div class="article-summary-box-inner">
<span><p>In this work, we present to the NLP community, and to the wider research
community as a whole, an application for the diachronic analysis of research
corpora. We open source an easy-to-use tool coined: DRIFT, which allows
researchers to track research trends and development over the years. The
analysis methods are collated from well-cited research works, with a few of our
own methods added for good measure. Succinctly put, some of the analysis
methods are: keyword extraction, word clouds, predicting
declining/stagnant/growing trends using Productivity, tracking bi-grams using
Acceleration plots, finding the Semantic Drift of words, tracking trends using
similarity, etc. To demonstrate the utility and efficacy of our tool, we
perform a case study on the cs.CL corpus of the arXiv repository and draw
inferences from the analysis methods. The toolkit and the associated code are
available here: https://github.com/rajaswa/DRIFT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models. (arXiv:2108.08877v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08877">
<div class="article-summary-box-inner">
<span><p>We provide the first exploration of text-to-text transformers (T5) sentence
embeddings. Sentence embeddings are broadly useful for language processing
tasks. While T5 achieves impressive performance on language tasks cast as
sequence-to-sequence mapping problems, it is unclear how to produce sentence
embeddings from encoder-decoder models. We investigate three methods for
extracting T5 sentence embeddings: two utilize only the T5 encoder and one uses
the full T5 encoder-decoder model. Our encoder-only models outperforms
BERT-based sentence embeddings on both transfer tasks and semantic textual
similarity (STS). Our encoder-decoder method achieves further improvement on
STS. Scaling up T5 from millions to billions of parameters is found to produce
consistent improvements on downstream tasks. Finally, we introduce a two-stage
contrastive learning approach that achieves a new state-of-art on STS using
sentence embeddings, outperforming both Sentence BERT and SimCSE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Recurrent multiple shared layers in Depth for Neural Machine Translation. (arXiv:2108.10417v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10417">
<div class="article-summary-box-inner">
<span><p>Learning deeper models is usually a simple and effective approach to improve
model performance, but deeper models have larger model parameters and are more
difficult to train. To get a deeper model, simply stacking more layers of the
model seems to work well, but previous works have claimed that it cannot
benefit the model. We propose to train a deeper model with recurrent mechanism,
which loops the encoder and decoder blocks of Transformer in the depth
direction. To address the increasing of model parameters, we choose to share
parameters in different recursive moments. We conduct our experiments on WMT16
English-to-German and WMT14 English-to-France translation tasks, our model
outperforms the shallow Transformer-Base/Big baseline by 0.35, 1.45 BLEU
points, which is 27.23% of Transformer-Big model parameters. Compared to the
deep Transformer(20-layer encoder, 6-layer decoder), our model has similar
model performance and infer speed, but our model parameters are 54.72% of the
former.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-08-28 23:09:17.986847123 UTC">2021-08-28 23:09:17 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.1</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>